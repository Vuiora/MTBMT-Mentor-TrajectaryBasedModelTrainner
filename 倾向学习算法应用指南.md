# 倾向学习算法应用指南

## 概述

本指南说明如何使用本系统实现**倾向学习算法**，包括：
1. 生成分布学习模型（多个决策树）
2. 提取算法轨迹（状态序列、倾向值、选择路径）
3. 记录经验特征（目标倾向、检索时间、轨迹长度）
4. 中心学习模型整合经验
5. 实现算法指导

## 核心概念回顾

### 1. 算法状态 (Algorithm State)
- **定义**: 当前算法的所有可被观测的状态
- **实现**: 决策树中的每个节点

### 2. 算法轨迹 (Algorithm Trajectory)
- **定义**: 顺序上按时序排列相邻的一系列状态
- **实现**: `sequence` 数组（状态序列）

### 3. 倾向 (Tendency)
- **定义**: 轨迹的变化方向
- **实现**: `tendency` 数组（每个状态的倾向值）

### 4. 倾向学习算法 (Tendency Learning Algorithm)
- **定义**: 通过学习机器学习算法倾向学习的量化模式，为相似结构/情况/经验的机器学习算法提供学习指导
- **实现**: `Trajectary` 类 + 特征相关性量化分析

### 5. 算法指导 (Algorithm Guidance)
- **定义**: 在算法训练过程中，通过纠正算法的学习轨迹来改变学习函数或超参数
- **实现**: 基于轨迹质量分析调整算法参数

## 完整工作流程

### 步骤1: 生成分布学习模型

```python
from generate_decision_tree_trajectories import main

# 生成多个分布学习模型（决策树）
# 包括：好的树、过拟合的树、欠拟合的树、分类不合格的树
trajectories, trees = main(
    use_validation_set=True,    # 使用三部分数据划分
    use_multiple_trees=True,    # 生成多个决策树
    n_trees=25                  # 生成25个分布学习模型
)

print(f"生成了 {len(trajectories)} 条算法轨迹")
print(f"来自 {len(trees)} 个分布学习模型")
```

**输出**:
- `all_trajectories.json`: 所有轨迹数据（25,000条）
- 每个轨迹包含：算法状态序列、倾向值、选择路径、经验特征

### 步骤2: 中心学习模型整合经验

```python
from trajectary import Trajectary
import json
import numpy as np

# 加载所有轨迹（来自多个分布学习模型）
with open("all_trajectories.json", "r", encoding="utf-8") as f:
    all_trajectories = json.load(f)

# 中心学习模型：整合所有经验
# 为每个轨迹创建 Trajectary 对象，量化特征相关性
all_features = []
all_labels = []

for traj in all_trajectories:
    # 创建 Trajectary 对象（中心学习模型）
    trajectary = Trajectary("", trajectory_dict=traj)
    
    # 特征相关性量化分析（基本方法论）
    # 量化倾向、序列、选择之间的相关性
    features = trajectary.cal_mixed_tendency_sequence_selection(
        method='full',  # 使用最完整的量化方法
        normalize=False
    )
    
    # 记录经验特征
    all_features.append(features.flatten())
    all_labels.append({
        "retrieval_time": traj["retrieval_time"],
        "trajectory_length": traj["trajectory_length"],
        "decision_effect": traj["decision_effect"]  # 目标倾向
    })

# 转换为特征矩阵
X = np.array(all_features)
y = np.array([label["decision_effect"] for label in all_labels])

print(f"特征矩阵形状: {X.shape}")
print(f"目标倾向范围: {y.min():.4f} - {y.max():.4f}")
```

### 步骤3: 倾向学习 - 学习轨迹模式

```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score

# 训练倾向学习模型
# 学习轨迹模式与决策效果（目标倾向）的关联
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 倾向学习算法：学习轨迹模式
tendency_learning_model = RandomForestRegressor(
    n_estimators=100,
    random_state=42
)
tendency_learning_model.fit(X_train, y_train)

# 评估模型
y_pred = tendency_learning_model.predict(X_test)
r2 = r2_score(y_test, y_pred)

print(f"倾向学习模型 R2 分数: {r2:.4f}")
print("模型已学习轨迹模式与决策效果的关联")
```

### 步骤4: 算法指导 - 识别高质量轨迹模式

```python
# 使用倾向学习模型预测哪些轨迹可能生成最好的树
predictions = tendency_learning_model.predict(X)

# 找出预测成功率最高的轨迹（前100个）
best_indices = np.argsort(predictions)[-100:]
best_trajectories = [all_trajectories[i] for i in best_indices]

print(f"\n预测可能生成最好树的轨迹（前100个）:")
print(f"  平均预测成功率: {np.mean(predictions[best_indices]):.4f}")
print(f"  实际平均成功率: {np.mean([t['decision_effect'] for t in best_trajectories]):.4f}")

# 分析高质量轨迹的特征
best_lengths = [t["trajectory_length"] for t in best_trajectories]
best_tendencies = [np.mean(t["tendency"]) for t in best_trajectories]

print(f"\n高质量轨迹的特征:")
print(f"  平均轨迹长度: {np.mean(best_lengths):.2f} 节点")
print(f"  平均倾向值: {np.mean(best_tendencies):.4f}")
```

### 步骤5: 基于轨迹模式调整算法参数

```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import make_classification

# 基于高质量轨迹模式调整新算法的参数
# 这是算法指导的核心：通过纠正算法的学习轨迹来改变学习函数或超参数

# 分析高质量轨迹的特征
avg_length = np.mean(best_lengths)
avg_tendency = np.mean(best_tendencies)

# 基于特征调整新算法的参数
# 例如：基于轨迹长度调整树的深度
recommended_max_depth = int(avg_length * 1.2)

print(f"\n基于轨迹模式推荐的参数:")
print(f"  推荐最大深度: {recommended_max_depth}")

# 使用推荐的参数训练新算法
X_new, y_new = make_classification(
    n_samples=10000,
    n_features=30,
    n_informative=15,
    n_classes=5,
    random_state=42
)

# 算法指导：使用调整后的参数
guided_tree = DecisionTreeClassifier(
    max_depth=recommended_max_depth,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42
)

guided_tree.fit(X_new, y_new)
guided_score = guided_tree.score(X_new, y_new)

print(f"  指导后的算法准确率: {guided_score:.4f}")
```

## 高级应用：特征相关性量化方法选择

### 问题：如何选择最优的量化算法？

根据基本方法论，我们需要：
1. 使用特征相关性量化分析的算法
2. 总结对于各特征相关性分析的算法的量化
3. 选取最优的量化算法进行使用
4. 记录该模式的经验特征

### 解决方案：评估不同量化方法

```python
from trajectary import Trajectary
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score

# 不同的量化方法
methods = ['concatenate', 'with_interaction', 'with_statistics', 'full']

method_scores = {}

for method in methods:
    # 为每个轨迹量化特征相关性
    all_features = []
    all_labels = []
    
    for traj in all_trajectories[:1000]:  # 使用部分数据快速评估
        trajectary = Trajectary("", trajectory_dict=traj)
        features = trajectary.cal_mixed_tendency_sequence_selection(
            method=method,
            normalize=False
        )
        all_features.append(features.flatten())
        all_labels.append(traj["decision_effect"])
    
    X = np.array(all_features)
    y = np.array(all_labels)
    
    # 评估该方法的效果
    model = RandomForestRegressor(n_estimators=50, random_state=42)
    scores = cross_val_score(model, X, y, cv=5, scoring='r2')
    
    method_scores[method] = {
        'mean_score': np.mean(scores),
        'std_score': np.std(scores)
    }
    
    print(f"{method}: R2 = {np.mean(scores):.4f} ± {np.std(scores):.4f}")

# 选择最优的量化算法
best_method = max(method_scores, key=lambda k: method_scores[k]['mean_score'])
print(f"\n最优量化方法: {best_method}")
print(f"  平均 R2: {method_scores[best_method]['mean_score']:.4f}")
```

## 中心学习模型 vs 分布学习模型

### 分布学习模型（边缘学习模型）

```python
# 分布学习模型：各个独立的决策树
# 在特定场景下学习，将经验传递给中心学习模型

distribution_models = []
for config in tree_configs:
    # 每个分布模型在特定参数下学习
    clf = DecisionTreeClassifier(**config)
    clf.fit(X_train, y_train)
    
    # 提取经验（轨迹 + 决策效果）
    extractor = DecisionTreeTrajectoryExtractor(clf)
    trajectories = extractor.extract_trajectories_batch(X_val, y_val)
    
    # 记录经验特征（目标倾向）
    for traj in trajectories:
        traj["decision_effect"] = clf.score(X_test, y_test)
    
    distribution_models.append({
        "model": clf,
        "trajectories": trajectories,
        "experience": clf.score(X_test, y_test)
    })
```

### 中心学习模型（广泛学习模型）

```python
# 中心学习模型：整合所有分布模型的经验
# 具有更多的经验，但经验更多来自分布模型

# 整合所有分布模型的经验
all_experiences = []
for dist_model in distribution_models:
    all_experiences.extend(dist_model["trajectories"])

# 中心学习模型学习所有经验
central_model = Trajectary("", trajectory_dict=all_experiences[0])
# ... 使用所有经验进行学习
```

## 实际应用示例

### 示例1: 识别过拟合轨迹

```python
# 识别过拟合的轨迹模式
overfitting_trajectories = [
    t for t in all_trajectories 
    if t.get("is_overfitting", False)
]

# 分析过拟合轨迹的特征
overfitting_lengths = [t["trajectory_length"] for t in overfitting_trajectories]
overfitting_tendencies = [np.mean(t["tendency"]) for t in overfitting_trajectories]

print("过拟合轨迹的特征:")
print(f"  平均轨迹长度: {np.mean(overfitting_lengths):.2f}")
print(f"  平均倾向值: {np.mean(overfitting_tendencies):.4f}")

# 算法指导：避免这些特征
# 例如：如果过拟合轨迹通常很长，则限制树的深度
```

### 示例2: 识别高质量轨迹

```python
# 识别高质量的轨迹模式
high_quality_trajectories = [
    t for t in all_trajectories 
    if t["decision_effect"] > 0.70
]

# 分析高质量轨迹的特征
high_quality_lengths = [t["trajectory_length"] for t in high_quality_trajectories]
high_quality_tendencies = [np.mean(t["tendency"]) for t in high_quality_trajectories]

print("高质量轨迹的特征:")
print(f"  平均轨迹长度: {np.mean(high_quality_lengths):.2f}")
print(f"  平均倾向值: {np.mean(high_quality_tendencies):.4f}")

# 算法指导：鼓励这些特征
# 例如：如果高质量轨迹通常长度适中，则设置合适的深度
```

## 总结

本系统实现了完整的**倾向学习算法**框架：

1. ✅ **算法状态**: 决策树节点
2. ✅ **算法轨迹**: 状态序列（sequence）
3. ✅ **倾向**: 轨迹变化方向（tendency）
4. ✅ **倾向学习**: 通过量化轨迹模式学习经验
5. ✅ **算法指导**: 基于轨迹模式调整算法参数
6. ✅ **中心学习模型**: 整合分布学习模型的经验
7. ✅ **特征相关性量化**: 多种量化方法，选择最优方法

通过这个框架，我们可以：
- 学习哪些轨迹模式能产生更好的决策效果
- 识别需要调整的轨迹模式（过拟合、欠拟合）
- 基于轨迹模式调整算法参数
- 实现算法选择和算法指导

