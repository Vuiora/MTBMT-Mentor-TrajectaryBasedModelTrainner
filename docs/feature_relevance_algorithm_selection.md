 ## 目标与核心思想
 
 我们要解决的问题是：**对“特征—目标”的相关性/重要性进行可比较的量化**，并在不同数据条件下**自动选择最优量化算法**，同时把选择过程沉淀为“经验特征”，用于后续任务的算法选择与训练指导。
 
 本质是两层学习：
 
 - **第一层（相关性量化）**：给定数据 \(D=(X,y)\)，用某个相关性/重要性算法 \(A\) 产生特征分数向量 \(s=A(D)\)。
 - **第二层（元学习）**：学习映射 \(f:\)（数据集元特征、学习轨迹特征）\(\rightarrow\) 最优算法/策略，使得在新数据上直接推荐 \(A^\*\) 或给出组合/加权策略。
 
 ---
 
 ## 一、特征相关性/重要性量化算法谱系（可量化对比）
 
 下面按“假设能力—可解释性—计算成本”将常见算法分组，统一输出为每特征一个分数（越大越相关/重要）。
 
 ### 1) 线性相关类（快速、强假设）
 
 - **Pearson 相关（|r|）**：刻画线性相关；对异常值敏感；适合连续变量+近线性。
 - **Spearman 相关（|ρ|）**：刻画单调相关；对非线性单调更稳健。
 
 适用经验：
 - 低噪声、近线性、特征间共线性不极端时表现好；成本低、稳定性高。
 
 ### 2) 信息论类（非线性能力、更稳健但更敏感）
 
 - **互信息（MI）**：捕捉非线性依赖；对估计方式（kNN/离散化）敏感；需稳定性评估配合。
 - 相关扩展：条件互信息、mRMR（最大相关最小冗余，偏“子集选择”）。
 
 适用经验：
 - 目标与特征存在明显非线性依赖；但样本较少/噪声较大时 MI 易波动，应配合重采样稳定性。
 
 ### 3) 距离/核相关类（更强的非线性刻画）
 
 - **距离相关（dCor）**：只要存在任何依赖通常可被检出；朴素实现为 \(O(n^2p)\)（大样本需近似/抽样）。
 - **HSIC（核独立性检验）**：核方法表达力强；需要核与带宽选择。
 
 适用经验：
 - 强非线性/多模态依赖；当 n 不大但关系复杂时往往优于 Pearson/Spearman。
 
 ### 4) 基于模型的重要性（贴近下游任务、但引入模型偏置）
 
 - **Permutation Importance（置换重要性）**：模型无关；分数解释直观；成本较高；对强共线性会“分摊/漂移”。
 - **树模型内置重要性（gain/impurity）**：快但有偏（偏向高基数/连续特征）。
 - **线性模型系数（Lasso/ElasticNet）**：强假设但可解释；适合稀疏线性。
 - **SHAP**：解释力强但工程成本高。
 
 适用经验：
 - 当最终模型结构确定时（例如 GBDT/NN），用与下游一致的模型重要性更贴近最终收益；同时必须评估稳定性与成本。
 
 ---
 
 ## 二、统一量化输出与“可比较指标”
 
 ### 统一输出（必选）
 
 对任意方法 \(A\)，输出：
 
 - **scores**：\(s\in \mathbb{R}^p\)，每特征一个分数（越大越相关/重要）
 - **uncertainty（可选）**：\(u\in \mathbb{R}^p\)，分数的不确定性/不稳定程度（例如置换重要性的 std）
 - **meta**：耗时、参数、估计方式等元信息
 
 ### 可比较评价指标（用于选“最优量化算法”）
 
 用一组指标把“相关性算法”变成可比较对象（跨任务/跨数据）：
 
 - **下游效用（Utility）**：选 top-k 特征训练轻量模型，做 CV 得分（AUC/Acc/R2…）
 - **稳定性（Stability）**：不同折/重采样下 top-k 集合的 Jaccard 平均；或重要性排名的 Spearman 一致性
 - **鲁棒性（Robustness）**：对噪声注入/缺失扰动后的分数漂移（可选）
 - **成本（Cost）**：运行时间、内存、超参敏感度
 - **一致性（Consistency）**：与已知先验（领域规则/单调约束）的一致程度（可选）
 
 ### 综合打分（示例）
 
 给定方法 \(A\) 的评估输出，定义综合目标（可按业务加权）：
 
 \[
 J(A)=w_u\cdot \text{Utility}(A)+w_s\cdot \text{Stability}(A)-w_c\cdot \log(1+\text{Cost}(A))
 \]
 
 然后选 \(A^\*=\arg\max_A J(A)\)。
 
 ---
 
 ## 三、元学习：用“数据元特征 + 学习轨迹特征”做算法选择/指导
 
 ### 1) 数据集元特征（Meta-features）
 
 目标：低成本、可泛化、与算法适配性强。常用：
 
 - **规模与维度**：n、p、p/n
 - **缺失/稀疏**：missing_rate、近零比例
 - **目标形态**：分类/回归、类别数、是否严重不均衡
 - **相关结构**：特征间平均 |Pearson|（共线性强弱）
 - （可扩展）非线性迹象：简单模型 vs 非线性模型的增益差、分布偏态/峰度等
 
 ### 2) 学习轨迹特征（Trajectory-features）
 
 从“训练过程曲线”提炼可泛化信息，用于指导选择：
 
 - loss/score 曲线：早期斜率、后期斜率、最优点位置、AUC、波动（diff_std）
 - 特征重要性随迭代变化：top-k 稳定性曲线、重要性集中度随迭代变化
 - 梯度/更新范数：是否存在震荡、是否过早停滞
 
 直觉：当训练曲线表现出“强非线性/强交互”迹象时，优先选择 MI/dCor/模型重要性；当曲线平滑且线性模型即可拟合时，优先 Pearson/Spearman/Lasso 类。
 
 ### 3) 元学习任务定义
 
 - **分类式选择器**：输入（元特征、轨迹特征），输出“最佳相关性算法标签”
 - **排序/回归式选择器**：预测每个算法的 \(J(A)\)，再取最大
 - **策略输出（指导）**：输出“算法 + 参数 + 预算”组合，例如：
   - n 小：用 Spearman + 重采样稳定性
   - n 中且非线性：MI(k=3/5) 并取稳定 top-k
   - 共线性强：Permutation importance 配合分组/聚类特征
 
 ---
 
 ## 四、经验特征沉淀（Experience Store）
 
 建议以 JSONL 形式存每次任务的经验记录，最小字段：
 
 - dataset_id
 - meta_features（数据元特征）
 - trajectory_features（可选）
 - evaluations（每个方法的 utility/stability/cost 等）
 - selected_method（最优方法）
 - selection_reason（为什么这么选：规则/模型输出/权重）
 - created_at
 
 经验库的作用：
 
 - 离线训练元学习器
 - 在线检索相似数据集，做 case-based 推理
 - 回溯“为什么某次选错”，更新权重/特征
 
 ---
 
 ## 五、仓库内最小实现对应关系
 
 - `mtbmt/relevance/*`：相关性/重要性算法（统一输出 `RelevanceResult`）
 - `mtbmt/evaluation.py`：统一对比评价（utility/stability/cost）
 - `mtbmt/meta_features.py`：数据集元特征提取
 - `mtbmt/trajectory.py`：学习轨迹特征提取（对接训练日志即可）
 - `mtbmt/experience_store.py`：经验库 JSONL 追加
 - `mtbmt/meta_learner.py`：元学习选择器 baseline（RandomForest）
 - `scripts/benchmark_relevance.py`：端到端基准 + 写入经验库
