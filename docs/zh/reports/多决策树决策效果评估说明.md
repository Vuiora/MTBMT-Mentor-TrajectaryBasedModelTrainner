# 多决策树决策效果评估说明

## 概述

已实现生成多个决策树（必要的和不必要的），并在测试集上评估每个决策树的**决策成功率**，将成功率作为每条轨迹的 `decision_effect` 标签。

## 核心改进

### 1. 生成多个决策树

系统现在可以生成多个不同参数的决策树：
- **必要的决策树**：合理的参数配置
- **不必要的决策树**：过拟合或欠拟合的参数配置

### 2. 决策成功率评估

每个决策树在**测试集**上评估决策成功率：
```python
test_score = clf.score(X_test, y_test)  # 测试集准确率 = 决策成功率
```

这个成功率作为该决策树所有轨迹的 `decision_effect` 标签。

## 决策树配置

### 必要的决策树（7个）

1. **必要-浅树**: max_depth=10
   - 决策成功率: ~0.67
   - 特点: 浅层树，避免过拟合

2. **必要-中等深度**: max_depth=20
   - 决策成功率: ~0.70
   - 特点: 平衡的深度

3. **必要-深树**: max_depth=30
   - 决策成功率: ~0.70
   - 特点: 深层树

4. **必要-很深树**: max_depth=50
   - 决策成功率: ~0.70
   - 特点: 非常深的树

5. **必要-精细分裂**: min_samples_split=2, min_samples_leaf=1
   - 决策成功率: ~0.70
   - 特点: 精细的分裂策略

6. **必要-粗分裂**: min_samples_split=10, min_samples_leaf=5
   - 决策成功率: ~0.71
   - 特点: 粗粒度的分裂策略（可能更好）

7. **必要-信息熵**: criterion='entropy'
   - 决策成功率: ~0.71
   - 特点: 使用信息熵作为分裂标准

### 不必要的决策树（3个）

1. **不必要-过浅**: max_depth=3
   - 决策成功率: ~0.41
   - 特点: 严重欠拟合

2. **不必要-过深**: max_depth=100
   - 决策成功率: ~0.69
   - 特点: 可能过拟合（训练准确率1.0）

3. **不必要-欠拟合**: min_samples_split=100, min_samples_leaf=50
   - 决策成功率: ~0.68
   - 特点: 过于保守的分裂策略

## 决策成功率统计

从实际运行结果：

```
决策效果(成功率)统计:
  平均决策成功率: 0.6660
  最低决策成功率: 0.4061 (不必要-过浅)
  最高决策成功率: 0.7127 (必要-粗分裂)
  决策成功率标准差: 0.0875
```

### 按决策树分组

| 决策树类型 | 平均成功率 | 轨迹数 | 说明 |
|-----------|-----------|--------|------|
| 必要-粗分裂 | 0.7127 | 1000 | 最高成功率 |
| 必要-信息熵 | 0.7095 | 1000 | 使用信息熵 |
| 必要-中等深度 | 0.6999 | 1000 | 平衡配置 |
| 必要-精细分裂 | 0.6987 | 1000 | 精细分裂 |
| 必要-深树 | 0.6963 | 1000 | 深层树 |
| 必要-很深树 | 0.6953 | 1000 | 非常深的树 |
| 不必要-过深 | 0.6942 | 1000 | 过拟合风险 |
| 必要-浅树 | 0.6682 | 1000 | 浅层树 |
| 不必要-欠拟合 | 0.6787 | 1000 | 欠拟合 |
| 不必要-过浅 | 0.4061 | 1000 | 严重欠拟合 |

## 数据流

```
1. 生成数据集 (100,000样本)
   │
   ├─→ 训练集 (70,000) ──→ 训练10个不同的决策树
   │
   ├─→ 验证集 (15,000) ──→ 提取轨迹
   │
   └─→ 测试集 (15,000) ──→ 评估每个决策树的成功率
                            ↓
                    作为 decision_effect 标签
```

## 使用示例

### 生成多个决策树和轨迹

```python
from generate_decision_tree_trajectories import main

# 生成10个决策树，每个提取1000条轨迹
trajectories, trees = main(
    use_validation_set=True,    # 使用验证集（推荐）
    use_multiple_trees=True,     # 生成多个决策树
    n_trees=10                   # 生成10个决策树
)

# 查看轨迹的决策效果
for traj in trajectories[:5]:
    print(f"决策树: {traj['tree_name']}")
    print(f"决策成功率: {traj['decision_effect']:.4f}")
    print(f"轨迹长度: {traj['trajectory_length']}")
```

### 分析不同决策树的成功率

```python
import numpy as np
from collections import defaultdict

# 按决策树分组统计
tree_groups = defaultdict(list)
for traj in trajectories:
    tree_name = traj['tree_name']
    tree_groups[tree_name].append(traj['decision_effect'])

# 打印统计
for tree_name, effects in tree_groups.items():
    print(f"{tree_name}:")
    print(f"  平均成功率: {np.mean(effects):.4f}")
    print(f"  成功率范围: {np.min(effects):.4f} - {np.max(effects):.4f}")
```

## 决策效果标签说明

### decision_effect 的含义

- **定义**: 该决策树在测试集上的准确率（决策成功率）
- **范围**: 0.0 - 1.0
- **计算**: `clf.score(X_test, y_test)`
- **用途**: 作为监督学习的标签，评估轨迹质量

### 决策成功率的意义

1. **高成功率 (>0.70)**: 
   - 决策树性能好
   - 轨迹可能更有价值

2. **中等成功率 (0.60-0.70)**:
   - 决策树性能中等
   - 轨迹价值一般

3. **低成功率 (<0.60)**:
   - 决策树性能差（如过浅树）
   - 轨迹价值较低

## 轨迹数据格式

每条轨迹现在包含：

```json
{
    "tendency": [...],
    "sequence": [...],
    "selection": [...],
    "retrieval_time": 0.001,
    "trajectory_length": 16,
    "decision_effect": 0.7127,    // 该决策树的成功率
    "tree_name": "必要-粗分裂",    // 决策树名称
    "tree_idx": 5                 // 决策树索引
}
```

## 运行结果示例

```
生成 10 个不同参数的决策树
  必要-浅树: 成功率 0.6682
  必要-中等深度: 成功率 0.6999
  必要-深树: 成功率 0.6963
  必要-很深树: 成功率 0.6953
  必要-精细分裂: 成功率 0.6987
  必要-粗分裂: 成功率 0.7127 ← 最高
  必要-信息熵: 成功率 0.7095
  不必要-过浅: 成功率 0.4061 ← 最低
  不必要-过深: 成功率 0.6942
  不必要-欠拟合: 成功率 0.6787

总共生成 10,000 条轨迹（来自 10 个决策树）
每条轨迹的 decision_effect 是该决策树在测试集上的成功率
```

## 优势

1. **多样性**: 包含必要和不必要的决策树，覆盖不同场景
2. **真实性**: 决策成功率在测试集上评估，反映真实性能
3. **可比较性**: 所有轨迹都有明确的决策成功率标签
4. **数据丰富**: 来自多个决策树的轨迹提供更多训练数据

## 使用建议

1. **监督学习**: 使用 `decision_effect` 作为标签训练模型
2. **轨迹筛选**: 可以根据成功率筛选高质量轨迹
3. **模型分析**: 分析不同决策树参数对成功率的影响
4. **特征工程**: 使用决策成功率作为特征

## 总结

✅ **已实现**: 生成多个决策树（必要的和不必要的）
✅ **已实现**: 在测试集上评估每个决策树的成功率
✅ **已实现**: 将成功率作为轨迹的 `decision_effect` 标签
✅ **已验证**: 所有测试通过，功能正常

现在每条轨迹都有准确的决策成功率标签，可以用于监督学习！

